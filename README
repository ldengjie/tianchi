1.数据下载
1.1.Go to web to download .csv , copy address of them into download.sh,
    source download.sh
1.2.unzip user_balance_table.zip

2.数据预处理
2.1.replace constellation with integer
    source replaceConstellationIntoInteger.sh

2.2.vi user_balance_table.csv
   %s#,,#,0,#g  //more than two times
   %s#,$#,0#g

3. purchase_by_type_sum_p2_v4.csv,redeem_by_type_sum_p2_v4.csv 按金额大小和频率初步细分，间隔较小，需要下面的再聚类.

4. pu_cluster.R re_cluster.R 按金额大小和频率进行聚类

- EM
- HC
- HC-diss
- K-MEANS
- K-Medoids

综合上面的结果，进行分类,最终purchase分为"zfb1","zfb2","zfb3","bank1","bank2","bank3","share",redeem分为"zfb1","zfb2","consume","card1","card2","card3"

5. pu.dev.R re.dev.R 开发版本，主要功能在这里设计，包含了

- arima+lm,星期（1-6）+月初月末（-5，5）+节假日（-5，0，5）+6.18（-5，0，5）+春节（-5，0，5）+调休+time(1.2.3...)特征，当pq都为0时，相当于lm。加上这些特征后，arima部分相当于白噪声。循环知道每个特征和pq值95%置信度显著不为0.提取月初月末+节假日+调休特征值共后续使用。
- stlf-arima，特征如上
- stlf-ets,用上面月初月末+节假日+调休特征调整,即*holidayshift*monthshift
- tbats，periods=c(7,30.44,91.31),对应与星期、月、季度三个周期,*holidayshift*monthshift
- arima+wavelet,小波分析，分解为3+1，重构后分别用arima+特征,最后再合并这4部分
- arima+fourier,分为7/30.44两部分，k=3/15,这里15可改为3，即k=3/3，这样fre覆盖1：30.44,且没重合
- seasonal arima,季节趋势arima模型，除去月末月初的特征
- hw,平滑指数,*holidayshift*monthshift
- random forest,循环mtry 1:(NCOL(xregfit)-1),找出最小的MSE,*monthshift*holidayshift
- svm,用tune找出最优epsilon和cost,挺耗时间20min左右，存储起来以后直接调用即可,*holidayshift*monthshift

6. pu.R re.R 最终版的最精简代码，用于天池平台的代码review。没有注释。

v1 zfb:0-3 bank:0-11 from season 2 part1
v2 zfb:0-31 bank:0-41
v3 zfb:0-3 bank:0-3
v4 zfb:(0-3)*7 bank:(0-3)*7

过程总结：

5.21 得知比赛
5.24 提交C++版本结果,自己从0写的，现在看来是趋势+星期+月末月初+节假日特征的模型，1.去掉月末月初+节假日前后几天的数据，用来拟合趋势，然后计算星期的相对于趋势基准值的相对变化百分比，即乘法模型。2.去数据中去掉趋势+星期周期，计算月末月初+节假日变化相对百分比 3.上面的结合起来，乘法模型。 
5.24~6.15 空白
6.15~6.22 间歇调整参数，用for循环，调整前后天数+开始日期，用8月做预测区间，效果不明显。。。
6.28~7.1  接触到R。
7.2-7.16  改用R语言，尝试上面(5)中的各种模型
7.20-7.25 调参，考虑模型融合

R才是数据统计正道，可惜接触时间太晚，加上比赛时间仓促，模型参数调节没时间来得及进行。
